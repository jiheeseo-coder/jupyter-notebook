{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T07:46:41.019995Z",
     "start_time": "2020-12-29T07:46:37.944266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T07:46:41.340826Z",
     "start_time": "2020-12-29T07:46:41.021993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 3. 0. 0. 0. 0. 3. 3. 0. 0. 1. 3. 6. 6. 6. 1. 0. 3. 0. 1. 1. 0. 1.\n",
      " 5. 4. 4. 0. 0. 0. 5. 0. 0. 1. 3. 0. 0. 1. 3. 5. 5. 1. 5. 1. 0. 0. 6. 0.\n",
      " 0. 0. 0. 5. 4. 6. 0. 0. 1. 1. 1. 1. 3. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 6. 3. 0. 0. 2. 6. 1. 1. 2. 6. 3. 1. 0. 6. 3. 1. 5. 4. 2. 2. 3. 0. 0. 1.\n",
      " 0. 5. 0. 6. 1.]\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]], shape=(101, 7), dtype=float32)\n",
      "(101, 16) (101, 7)\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv', delimiter = ',', dtype = np.float32)\n",
    "# 동물의 특징을 추출하여 어떤 종류인지 추측하는 것\n",
    "    # numpy활용해 데이터를 로드함, ','로 데이터를 나눔\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, -1]\n",
    "    # x_data는 마지막 열을 빼고 가져온다\n",
    "    # y_data는 마지막 열만 가져온다.\n",
    "\n",
    "nb_classes = 7  # 0  ~6\n",
    "    # 종이 7종인지 알 수 있음.\n",
    "\n",
    "print(y_data)\n",
    "# Make Y data as onehot shape\n",
    "Y_one_hot = tf.one_hot(y_data.astype(np.int32), nb_classes)\n",
    "    # y값을 보면 onehot으로 이루어져 있지 않음 그래서 tf.one_hot()함수를 사용하여 원핫인코딩을 해줌\n",
    "    # 7개의 클래스와 y로 원핫을 해줌\n",
    "    # n차원에서 n+1차원으로, 한 차원이 추가됨\n",
    "print(Y_one_hot)\n",
    "\n",
    "print(x_data.shape, Y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T07:47:45.145024Z",
     "start_time": "2020-12-29T07:47:45.136020Z"
    }
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((16, nb_classes)), name = 'weight')\n",
    "b = tf.Variable(tf.random.normal((nb_classes,)), name = 'bias')\n",
    "variables = [W, b]\n",
    "\n",
    "def logit_fn(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# 학습을 하면서 정확도를 맞추기 위한 것으로 사용됨\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logit_fn(X))\n",
    "\n",
    "def cost_fn(X, Y):\n",
    "    logits = logit_fn(X)\n",
    "    cost_i = tf.keras.losses.categorical_crossentropy(y_true = Y, y_pred = logits,\n",
    "                                                      from_logits=True)\n",
    "        # 인자값으로 logits가 들어감\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "    return cost\n",
    "\n",
    "def grad_fn(X, Y):\n",
    "    with tf.GradientTape()  as tape:\n",
    "        loss = cost_fn(X, Y)\n",
    "        grads = tape.gradient(loss, variables)\n",
    "            # 경사하강법 사용\n",
    "        return grads\n",
    "\n",
    "# 얼마나 목표에 잘 도달하고 있나 확인하는 함수\n",
    "def prediction(X, Y):\n",
    "    pred = tf.argmax(hypothesis(X), 1)\n",
    "        # tf.keras.losses.categorical_crossentropy보다 간편하게 softmax함수로 가장 높은 값을 구할 \n",
    "        # 수 있음. 그래서 hypothesis()함수를 사용하는 것임.\n",
    "    correct_preditcion = tf.equal(pred, tf.argmax(Y,1))\n",
    "        # 실제 Y 값과 pred값이 같은지 계산\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_preditcion, tf.float32))\n",
    "        # 얼마나 맞았는지에 대한 평균을 구해 accuracy로 내보낸다.\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T07:47:47.932862Z",
     "start_time": "2020-12-29T07:47:45.570596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 1 Loss: 5.610101222991943, Acc: 0.1683168262243271\n",
      "Steps: 100 Loss: 0.6019306182861328, Acc: 0.8415841460227966\n",
      "Steps: 200 Loss: 0.38190871477127075, Acc: 0.9108911156654358\n",
      "Steps: 300 Loss: 0.2877010405063629, Acc: 0.9405940771102905\n",
      "Steps: 400 Loss: 0.23101474344730377, Acc: 0.9504950642585754\n",
      "Steps: 500 Loss: 0.19246312975883484, Acc: 0.9603960514068604\n",
      "Steps: 600 Loss: 0.16442003846168518, Acc: 0.9603960514068604\n",
      "Steps: 700 Loss: 0.14311203360557556, Acc: 0.9603960514068604\n",
      "Steps: 800 Loss: 0.12642519176006317, Acc: 0.9603960514068604\n",
      "Steps: 900 Loss: 0.11306186765432358, Acc: 0.9900990128517151\n",
      "Steps: 1000 Loss: 0.10216663777828217, Acc: 0.9900990128517151\n"
     ]
    }
   ],
   "source": [
    "def fit(X, Y, epochs = 1000, verbose = 100):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
    "        # 최적화 하는 방법\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        grads = grad_fn(X, Y)\n",
    "        optimizer.apply_gradients(zip(grads, variables))\n",
    "        if((i==0) | ((i+1) % verbose ==0)):\n",
    "            acc = prediction(X, Y).numpy()\n",
    "                # 정확도를 구해서 출력함.\n",
    "            loss = cost_fn(X, Y).numpy()\n",
    "            print('Steps: {} Loss: {}, Acc: {}'.format(i+1, loss, acc))\n",
    "           \n",
    "fit(x_data, Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
